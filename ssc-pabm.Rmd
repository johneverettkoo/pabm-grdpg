---
title: "Sparse Subspace Clustering for the Popularity Adjusted Block Model"
author: John Koo, Minh Tang, Michael Trosset
output:
  pdf_document:
    citation_package: natbib
    number_sections: yes
# output: html_document
fontsize: 12pt
# geometry: "left=1cm,right=1cm,top=1cm,bottom=1.5cm"
urlcolor: blue
header-includes:
- \usepackage{float}
- \usepackage{mathtools}
- \usepackage{natbib}
- \usepackage[linesnumbered,ruled,vlined]{algorithm2e} 
- \setcitestyle{numbers,square}
- \usepackage{verbatim}
bibliography: ssc.bib
abstract: |
  TODO
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      # eval = FALSE,
                      comment = NA, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.pos = 'H', 
                      fig.align = 'center', 
                      fig.height = 3, 
                      fig.width = 5, 
                      fig.dpi = 300)

options(xtable.comment = FALSE, 
        xtable.table.placement = 'H')
```

\newcommand{\diag}{\text{diag}}
\newcommand{\tr}{\text{Tr}}
\newcommand{\blockdiag}{\text{blockdiag}}
\newcommand{\indep}{\stackrel{\text{indep}}{\sim}}
\newcommand{\iid}{\stackrel{\text{iid}}{\sim}}
\newcommand{\Bernoulli}{\text{Bernoulli}}
\newcommand{\Betadist}{\text{Beta}}

# Introduction

## Notation

$P$ denotes the edge probability matrix for the PABM. 
$A_{ij} \indep Bernoulli(P_{ij})$ for $i > j$, and 
$A_{ji} = A_{ij}, A_{ii} = 0$ $\forall i, j \leq n$ to make $A$ the edge weight 
matrix for a hollow, unweighted, and undirected graph. $X$ is an ASE of $A$ 
while $Y$ is constructed using the popularity vectors $\{\lambda^{(kl)}\}_K$ 
and the projection matrix $\Pi$ as an ASE of $P$. $Z = X Q - Y$ for 
$Q = \arg\min\limits_{Q \in \mathbb{O}(p, q)} ||X Q - Y||_F$. Let 
$x_i^\top, y_i^\top, z_i^\top$ be the rows of $X, Y, Z$. 
$X^{(n)}$ represents the full $X$ matrix for a sample of size $n$. 
$X^{(n, k)}$ represents the $k$^th^ block of $X^{(n)}$. Similarly, $P^{(k, l)}$ 
is the $kl$^th^ block of $P$, $P^{(n)}$ specifies that $P$ is $n \times n$, and 
$P^{(n, k, l)}$ is the $kl$^th^ block of $P^{(n)}$.

# Main Results

**Theorem 1**. 
The subspace detection property holds for $Y$ with probability at least  
$1 - \sum_k^K n_k e^{-\sqrt{K (n_k - 1)}}$.

This falls out of Theorem 2.8 from \citet{soltanolkotabi2012}. The subspaces 
in $Y$ are orthogonal, so $\text{aff} (S_k, S_l) = 0$ $\forall k, l \leq K$.

**Property 2**.
By \citet{rubindelanchy2017statistical}, 
$\max_i ||Q_n x_i^{(n)} - y_i^{(n)}|| = 
\max_i ||z_i^{(n)}|| = \delta^{(n)} = 
O_P \big(\frac{(\log n)^c}{n^{1/2}} \big)$. 
Then $||Z^{(n)}||_F \to 0$, $\delta^{(n)} \to 0$, and 
$r(X^{(n, l)} Q^{(n, l)}) \to r(Y^{(n, l)})$. Here we assume 
$r(Y^{(n, l)}) > 0$ $\forall n > K + 1$ and $l \leq K$. 

**Theorem 3**. ***TODO***
Let $r_k^{(n)} = r(U^{(n, k)})$ and $\hat{r}_k^{(n)} = r(\hat{U}^{(n, k)})$. 
Then $|\hat{r}^{(n)}_k - r_k^{(n)}| = O_P(a_n)$. ($a_n \to 0$.)

Alternatively, suppose $r_k^{(n)} > \alpha$ for some $\alpha > 0$. 

**Property 4**. 
$P(\mu(Y^{(n, k)}) = 0) = 1$ \cite{soltanolkotabi2012}.

This also holds for $\mu(U^{(n, k)})$ where $U$ is the matrix of 
eigenvectors of $P$.

**Theorem 5**.
Let $P^{(n)} = U^{(n)} \Lambda^{(n)} (U^{(n)})^\top$ be the spectral 
decomposition of $P$. Let 
$A^{(n)} = \hat{U}^{(n)} \hat{\Lambda}^{(n)} (\hat{U}^{(n)})^\top$ be the
approximate spectral decomposition of $A^{(n)}$ where 
$\hat{U}^{(n)} \in \mathbb{R}^{n \times K^2}$. Then for some $a, c > 0$,
$P(\mu(\hat{U}^{(n, l)}) \leq 
4 (\log n_l (n_k + 1) + \log K + t) \frac{1}{K^2} 
a \frac{(\log n)^c}{n \sqrt{\rho_n}}) \geq 
1 - \frac{1}{K^2} \sum_{k \neq l} \frac{4 e^{-2 t}}{(n_k + 1) n_l}$.

Equivalently, we can say 
$\mu(\hat{U}^{(n, l)}) = 
O_P(\frac{\log n_l (n_k + 1) + \log K + t}{K^2} 
\frac{(\log n)^c}{n \sqrt{\rho_n}})$  
$= O_P(\frac{(\log n)^{c'}t}{n K^2 \sqrt{\rho_n}})$ if $n, t \gg K$.

**Theorem 6**. 
***TODO*** 
$P(\hat{\mu}_k^{(n)} > \hat{r}_k^{(n)}) = ???$

**Corollary**. 
If $n \geq M$, $\exists \lambda > 0$ such that the LASSO subspace detection 
property holds for $X^{(n)}$ with parameter $\lambda$.

This falls out of Theorem 6 of \citet{pmlr-v28-wang13} and Theorem 6 of this 
paper.