---
title: Popularity Adjusted Block Models are Generalized Random Dot Product Graphs
subtitle: Future Leaders Summit 2022 Lightning Presentation
author: John Koo, Indiana University
date: 'April 2022'
output: 
  beamer_presentation:
    fig_crop: no
    theme: 'default'
    colortheme: 'beaver'
    includes:
      in_header: page_headers.tex
header-includes:
- \usepackage{setspace}
- \usepackage{float}
- \usepackage{mathtools}
- \usepackage{natbib}
- \usepackage[linesnumbered,ruled,vlined]{algorithm2e} 
- \setcitestyle{numbers,square,comma}
- \usepackage{verbatim}
- \usepackage{amsthm}
- \usepackage{comment}
- \usepackage{graphicx}
- \setbeamertemplate{itemize items}[circle]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      comment = NA, 
                      warning = FALSE, 
                      message = FALSE,
                      fig.align = 'center',
                      fig.lp = '')
options(xtable.comment = FALSE, 
        xtable.table.placement = 'H')
library(ggplot2)
import::from(magrittr, `%>%`)
theme_set(theme_bw())

source('~/dev/pabm-grdpg/functions.R')
set.seed(314159)
```

## Contributors

::: columns

:::: {.column width='33%'}

```{r, out.width = '100px'}
knitr::include_graphics('john-koo.jpeg')
```

John Koo,  
PhD Student in Statistical Science,  
Indiana University

::::

:::: {.column width='33%'}

```{r, out.width = '100px'}
knitr::include_graphics('minh-tang.jpg')
```

Minh Tang,  
Assistant Professor of Statistics,  
NC State University

::::

:::: {.column width='33%'}

```{r, out.width = '100px'}
knitr::include_graphics('michael-trosset.jpg')
```

Michael Trosset,  
Professor of Statistics,  
Indiana University

::::

:::

## Community Detection for Networks

\newcommand{\diag}{\text{diag}}
\newcommand{\tr}{\text{Tr}}
\newcommand{\blockdiag}{\text{blockdiag}}
\newcommand{\indep}{\stackrel{\text{ind}}{\sim}}
\newcommand{\iid}{\stackrel{\text{iid}}{\sim}}
\newcommand{\Bernoulli}{\text{Bernoulli}}
\newcommand{\Betadist}{\text{Beta}}
\newcommand{\BG}{\text{BernoulliGraph}}
\newcommand{\Cat}{\text{Categorical}}
\newcommand{\Uniform}{\text{Uniform}}
\newcommand{\RDPG}{\text{RDPG}}
\newcommand{\GRDPG}{\text{GRDPG}}
\newcommand{\PABM}{\text{PABM}}

```{r out.width = '50%', fig.height = 3, fig.width = 4}
Pz <- generate.P.beta(64, 4, 4, 1, 1, 4)
P <- Pz$P
z <- Pz$clustering
A <- draw.graph(P)
qgraph::qgraph(A, groups = factor(z), legend = FALSE)
```

How can we cluster the nodes of a network?

Statistical inference (parametric approach):

1. Define a generative model for graph: 
$G \mid z_1, ..., z_n, \vec{\theta} \sim P(\vec{z}, \vec{\theta})$.
2. Develop a method for obtaining estimators: 
$f(G) = (\hat{\vec{z}}, \hat{\vec{\theta}})$.
3. Describe asymptotic properties of estimators: 
$(\hat{\vec{z}}, \hat{\vec{\theta}}) \to (\vec{z}, \vec{\theta})$.

## Bernoulli Graphs

<style type="text/css">
.caption {
    font-size: x-small;
}
</style>

::: columns

:::: {.column width=62.5%}

Let $G = (V, E)$ be an undirected and unweighted graph with $|V| = n$.

$G$ is described by adjacency matrix $A$ such that
$A_{ij} = \begin{cases} 
1 & \exists \text{ edge between } i \text{ and } j \\
0 & \text{else}
\end{cases}$

$A_{ji} = A_{ij}$ and $A_{ii} = 0$ $\forall i, j \in [n]$.

\vspace*{1\baselineskip}

$A \sim \BG(P)$ iff:

1. $P \in [0, 1]^{n \times n}$ describes edge probabilities between pairs of 
vertices.
2. $A_{ij} \indep \Bernoulli(P_{ij})$ for each $i < j$.

::::

:::: {.column width=37.5%}

**Example 1**: If every entry $P_{ij} = \theta$, then $A \sim \BG(P)$ is an Erdos-Renyi graph.  
For this model, $A_{ij} \iid \Bernoulli(\theta)$.

```{r, fig.height = 2, fig.width = 2}
n <- 2 ** 5
p <- 1 / log(n)
P <- matrix(p, nrow = n, ncol = n)
A <- draw.graph(P)
qgraph::qgraph(A, vsize = 4)
```

::::

:::

## Block Models

Suppose each vertex $v_1, ..., v_n$ has labels $z_1, ..., z_n \in \{1, ..., K\}$,  
and each $P_{ij}$ depends on labels $z_i$ and $z_j$.  
Then $A \sim \BG(P)$ is a *block model*.

**Example 2**: Stochastic Block Model with two communities

::: columns

:::: column

* $z_1, ..., z_n \in \{1, 2\}$
* $P_{ij} = \begin{cases} 
p & z_i = z_j = 1 \\
q & z_i = z_j = 2 \\
r & z_i \neq z_j
\end{cases}$

::::

:::: column

```{r, fig.height = 3, fig.width = 4, out.width = '100%'}
n1 <- 2 ** 5
n2 <- 2 ** 5
n <- n1 + n2
z <- c(rep(1, n1), rep(2, n2))
p <- 1/2
q <- 1/4
r <- 1/8
P <- matrix(r, nrow = n, ncol = n)
P[seq(n1), seq(n1)] <- p
P[seq(n1 + 1, n), seq(n1 + 1, n)] <- q
A <- draw.graph(P)
qgraph::qgraph(A, vsize = 4, groups = factor(z), legend = FALSE)
```

::::

:::

## Popularity Adjusted Block Model

**Def** Popularity Adjusted Block Model (Sengupta and Chen, 2017):

Let each vertex $i \in [n]$ have $K$ popularity parameters
$\lambda_{i1}, ..., \lambda_{iK} \in [0, 1]$. 
Then $A \sim \PABM(\{\lambda_{ik}\}_K)$ if each $P_{ij} = \lambda_{i z_j} \lambda_{j z_i}$. 

**Lemma** (Noroozi, Rimal, and Pensky, 2020): 

$A$ is sampled from a PABM if $P$ can be described as:

1. Let each $P^{(kl)}$ denote the $n_k \times n_l$ matrix of edge probabilities 
between communities $k$ and $l$. 
2. Organize popularity parameters as vectors 
$\lambda^{(kl)} \in \mathbb{R}^{n_k}$ 
such that $\lambda^{(kl)}_i = \lambda_{k_i l}$ is the popularity parameter 
of the $i$^th^ vertex of community $k$ towards community $l$. 
3. Each block can be decomposed as 
$P^{(kl)} = \lambda^{(kl)} (\lambda^{(lk)})^\top$.

## Generalized Random Dot Product Graph

**Def** Generalized Random Dot Product Graph  
(Rubin-Delanchy, Cape, Tang, Priebe, 2020)

$A \sim \GRDPG_{p, q}(X)$ iff

* Latent vectors $x_1, ..., x_n \in \mathbb{R}^{p+q}$ such that 
$x_i^\top I_{p, q} x_j \in [0, 1]$ and $I_{p, q} = \blockdiag(I_p, -I_q)$
* $A \sim \BG(X I_{p, q} X^\top)$ where 
$X = \begin{bmatrix} x_1 & \cdots & x_n \end{bmatrix}^\top$
  * $P(\text{edge between } v_i, v_j) = x_i^\top I_{p,q} x_j$

## (Generalized) Random Dot Product Graph Model

### Recovery/Estimation

Want to estimate $X$ from $A$, or alternatively, 
interpoint distances, inner products, or angles.

### Adjacency Spectral Embedding

To embed in $\mathbb{R}^{p+q}$, 

1. Compute $A \approx \hat{V} \hat{\Lambda} \hat{V}^\top$ 
where $\hat{\Lambda} \in \mathbb{R}^{(p+q) \times (p+q)}$ and 
$\hat{V} \in \mathbb{R}^{n \times (p+q)}$ 
by using the $p$ most positive and $q$ most negative eigenvalues.

2. Let $\hat{X} = \hat{V} |\hat{\Lambda}|^{1/2}$.

\vspace*{.5\baselineskip}

$\max\limits_i \|\hat{X}_i - Q_n X_i \| = O_P \Big( \frac{(\log n)^c}{n^{1/2}} \Big)$
(Rubin-Delanchy et al., 2020)

## Connecting Block Models to the (G)RDPG Model

All Bernoulli Graphs are RDPG (if $P$ is 
positive semidefinite)  
or GRDPG (in general).

**Example 2** (cont'd): Assortative SBM ($p q > r^2$) with $K = 2$

::: columns

:::: column

$$P_{ij} = \begin{cases} 
p & z_i = z_j = 1 \\
q & z_i = z_j = 2 \\
r & z_i \neq z_j
\end{cases}$$

```{r fig.height = 3, fig.width = 6, out.width = '100%'}
qgraph::qgraph(A, vsize = 4, groups = factor(z), legend = FALSE)
```

::::

:::: column

$$P = 
\begin{bmatrix} 
P^{(11)} & P^{(12)} \\
P^{(21)} & P^{(22)}
\end{bmatrix} =
X X^\top$$

$$X = \begin{bmatrix} 
\sqrt{p} & 0 \\
\vdots & \vdots \\
\sqrt{p} & 0 \\
\sqrt{r^2 / p} & \sqrt{q - r^2 / p} \\
\vdots & \vdots \\
\sqrt{r^2 / p} & \sqrt{q - r^2 / p}
\end{bmatrix}$$

::::

:::

## Connecting Block Models to the (G)RDPG Model

**Example 2** (cont'd): If we want to perform community detection, 

1. Note that $A$ is a RDPG because $P = X X^\top$.
2. Compute the ASE $A \approx \hat{X} \hat{X}^\top$ with 
$\hat{X} = \hat{V} \hat{\Lambda}^{1/2}$.
3. Apply clustering algorithm (e.g., $K$-means) to $\hat{X}$,  
noting that as $n \to \infty$, the ASE approaches point masses.

```{r, fig.height = 5, fig.width = 5, out.width = '50%'}
P.eigen = eigen(P)
X <- P.eigen$vectors[, 1:2] %*% diag(P.eigen$values[1:2] ** .5)

A.eigen <- eigen(A)
X.hat <- A.eigen$vectors[, 1:2] %*% diag(A.eigen$values[1:2] ** .5)
plot(X.hat, asp = 1, col = z * 2, xlab = NA, ylab = NA, 
     main = 'ASE of the adjacency matrix drawn from SBM')
points(X, pch = 16, col = z * 2)
```

## Connecting Block Models to the (G)RDPG Model

::: columns

:::: column

```{r, out.width = '100%', fig.height = 4, fig.width = 4}
# par(mar = rep(1.75, 4))
plot(X, asp = 1, col = z, xlab = NA, ylab = NA, main = 'SBM: Point masses')
```

::::

:::: column

\vspace*{0\baselineskip}

```{r, out.width = '100%', fig.height = 4, fig.width = 4}
par(mar = rep(1.75, 4))
Pz <- generate.P.beta(n * 10)
P <- Pz$P
z <- Pz$clustering
X <- embedding(P, 3, 1)
pairs(X, col = z, asp = 1, pch = '.', main = 'PABM: Orthogonal subspaces')
```

::::

:::

## Connecting the PABM to the GRDPG

**Theorem** (KTT): $A \sim \PABM(\{\lambda^{(kl)}\}_K)$ is equivalent to 
$A \sim \GRDPG_{p, q}(X U)$ with

* $p = K (K + 1) / 2$, $q = K (K - 1) / 2$
* $U \in \mathbb{O}(K^2)$
* $X \in \mathbb{R}^{n \times K^2}$ is block diagonal and 
composed of $\{\lambda^{(kl)}\}_K$ 
with each block corresponding to a community.  

$$X = \begin{bmatrix}
\Lambda^{(1)} & \cdots & 0 \\
0 & \ddots & 0 \\
0 & \cdots & \Lambda^{(K)}
\end{bmatrix} 
\in \mathbb{R}^{n \times K^2}$$

$$\Lambda^{(k)} = \begin{bmatrix} 
\lambda^{(k1)} & \cdots & \lambda^{(kK)} 
\end{bmatrix} 
\in \mathbb{R}^{n_k \times K}$$

$$A \sim \PABM(\{\lambda_{ik}\}_K) \iff A \sim \GRDPG_{p, q}(X U)$$

## Orthogonal Spectral Clustering

**Theorem** (KTT): 
If $P = V \Lambda V^\top$ and $B = n V V^\top$,  
then $B_{ij} = 0$ if $z_i \neq z_j$.

**Algorithm**: Orthogonal Spectral Clustering:

1. Let $V$ be the eigenvectors of $A$ corresponding to the $K (K+1)/2$ most 
positive and $K (K-1) / 2$ most negative eigenvalues.
2. Compute $B = |n V V^\top|$ applying $|\cdot|$ entry-wise.
3. Construct graph $G$ using $B$ as its similarity matrix.
4. Partition $G$ into $K$ disconnected subgraphs.

**Theorem** (KTT): 
Let $\hat{B}_n$ with entries $\hat{B}_n^{(ij)}$ be the affinity matrix from OSC. 
Then $\forall$ pairs $(i, j)$ belonging to different communities 
and sparsity factor satisfying $n \rho_n = \omega\big((\log n)^{4c}\big)$, 

$$
\max_{i, j} \hat{B}^{(ij)}_n = 
O_P \Big( \frac{(\log n)^c}{\sqrt{n \rho_n}} \Big)
$$

## Simulation Results

Simulation setup:

1. $z_1, ..., z_n \iid \Cat(1/K, ..., 1/K)$
2. $\lambda_{ik} \iid \Betadist(a_{ik}, b_{ik})$  
$a_{ik} = \begin{cases} 2 & z_i = k \\ 1 & z_i \neq k \end{cases}$ 
$b_{ik} = \begin{cases} 1 & z_i = k \\ 2 & z_i \neq k \end{cases}$
3. $P_{ij} = \lambda_{i z_j} \lambda_{j z_i}$
4. $A \sim \BG(P)$

```{r, fig.height = 3, fig.width = 8, out.width = '100%'}
clustering.df <- readr::read_csv('~/dev/pabm-grdpg/simulation-results/cluster-sim-balanced.csv')

clustering.df %>%
  dplyr::group_by(n, K) %>%
  dplyr::summarise(
    med.err = median(error.osc),
    first.q = quantile(error.osc, .25),
    third.q = quantile(error.osc, .75),
    med.err.ssc = median(error.ssc.ase),
    first.q.ssc = quantile(error.ssc.ase, .25),
    third.q.ssc = quantile(error.ssc.ase, .75),
    med.err.louvain = median(error.louvain),
    first.q.louvain = quantile(error.louvain, .25),
    third.q.louvain = quantile(error.louvain, .75),
    med.err.ssc.A = median(error.ssc.A),
    first.q.ssc.A = quantile(error.ssc.A, .25),
    third.q.ssc.A = quantile(error.ssc.A, .75)
  ) %>% 
  dplyr::ungroup() %>% 
  ggplot() +
  theme_bw() + 
  theme(legend.position = 'bottom') + 
  scale_x_log10(breaks = c(128, 256, 512, 1024, 2048, 4096),
                labels = c(expression(2^7), 
                           expression(2^8), 
                           expression(2^9), 
                           expression(2^10), 
                           expression(2^11), 
                           expression(2^12))) +
  scale_y_log10() + 
  labs(y = 'community detection error count', 
       colour = NULL, shape = NULL) +
  geom_line(aes(x = n, y = med.err * n,
                colour = 'OSC')) +
  geom_point(aes(x = n, y = med.err * n,
                 colour = 'OSC', shape = 'OSC')) +
  geom_errorbar(aes(x = n, ymin = first.q * n, ymax = third.q * n,
                    colour = 'OSC'), width = .1) + 
  geom_line(aes(x = n, y = med.err.ssc * n,
                colour = 'SSC-ASE')) +
  geom_point(aes(x = n, y = med.err.ssc * n,
                 colour = 'SSC-ASE', shape = 'SSC-ASE')) +
  geom_errorbar(aes(x = n, ymin = first.q.ssc * n, ymax = third.q.ssc * n,
                    colour = 'SSC-ASE'), width = .1) +
  geom_line(aes(x = n, y = med.err.ssc.A * n,
                colour = 'SSC-A')) +
  geom_point(aes(x = n, y = med.err.ssc.A * n,
                 colour = 'SSC-A', shape = 'SSC-A')) +
  geom_errorbar(aes(x = n, ymin = first.q.ssc.A * n, ymax = third.q.ssc.A * n,
                    colour = 'SSC-A'), width = .1) +
  geom_line(aes(x = n, y = med.err.louvain * n,
                colour = 'MM-Louvain')) + 
  geom_point(aes(x = n, y = med.err.louvain * n,
                 colour = 'MM-Louvain', shape = 'MM-Louvain')) + 
  geom_errorbar(aes(x = n, ymin = first.q.louvain * n, ymax = third.q.louvain * n,
                    colour = 'MM-Louvain'), width = .1) + 
  scale_colour_brewer(palette = 'Set1') + 
  facet_wrap(~ K, labeller = 'label_both')
```

## Conclusion

1. The PABM is a recently developed flexible block model that can be used to describe graphs with community structure.

2. The GRDPG, which can describe all block models, motivates a spectral approach to statistical inference on graphs.

3. Under the GRDPG framework, the PABM with $K$ communities can be induced by a latent configuration in $\mathbb{R}^{K^2}$ consisting of $K$ $K$-dimensional subspaces that are orthogonal to each other.

4. The latent configuration of the PABM under the GRDPG framework leads to an intuitive method for community detection with nice theoretical asymptotic properties. 
